{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tOtCcYNDlYkg"
      },
      "source": [
        "Руководство по проверке гипотез\n",
        "Ресурсы\n",
        "Избыточные новости / Контрольные таблицы\n",
        "\n",
        "- [CodeAcademy Hypothesis Testing Slideshow](https://drive.google.com/open?id=1p4R2KCErq_iUO-wnfDrGPukTgQDBNoc7)\n",
        "- [Cheatsheet: Hypothesis Testing with Scipy](https://drive.google.com/open?id=1EY4UCg20HawWlWa50M2tFauoKBQcFFAW)\n",
        "\n",
        "- [Choosing Between Parametric and Non-Parametric Tests](https://blog.minitab.com/blog/adventures-in-statistics-2/choosing-between-a-nonparametric-test-and-a-parametric-test)\n",
        "\n",
        "#### Достоверные статистические данные\n",
        "\n",
        "- [Graphpad Prism's Stat Guide](https://www.graphpad.com/guides/prism/8/statistics/index.htm)\n",
        "- [LAERD Statistics Test Selector](https://statistics.laerd.com/premium/sts/index.php)\n",
        "\n",
        "___\n",
        "\n",
        "# Выбор корректного критерия проверки гипотезы\n",
        "\n",
        "## Шаг 0: Формулировка нашей гипотезы\n",
        "\n",
        "- **Прежде чем выбрать правильный критерий проверки гипотезы, вы должны сначала сформулировать свою нулевую гипотезу ($H_0$) и альтернативную ($H_A$ or $H_1$)**\n",
        "\n",
        "- **Вначале необходимо ответить на следующие вопросы**\n",
        "    1. Какой вопрос нужно задать ?\n",
        "    2. Какие значения необходимы для ответа на данный вопрос?\n",
        "    3. Возможно выборки которые необходимы будут отличаться? (например по количеству).\n",
        "        \n",
        "- **Сформулируем гипотезы:**\n",
        "\n",
        "    - $H_1$ :  \n",
        "\n",
        "    - $H_0$ :\n",
        "\n",
        "\n",
        "\n",
        "## ШАГ 1: Определите критерий проверки гипотез в зависимости от типа данных исследуемого признака.\n",
        "\n",
        "### Вопрос 1: Какие данные передо мной (Числовые или категориальные?)\n",
        "\n",
        "### Вопрос 2: Сколько выборок я буду рассматривать(мужчины и женщины - значит 2)?\n",
        "\n",
        "- Используя ответы на эти 2 вопроса: выбираем нужный критерий по таблице ниже.\n",
        "\n",
        "| Сколько выборок? | Числовые данные | Категориальные данные|\n",
        "| --- | --- | --- |\n",
        "|1 Выборка|1 T-критерий для одной выборки| Биноминальный тест|\n",
        "|2 Выборки | T-критерий дл 2 - х выборок| Хи - квадрат|\n",
        "|Более 2 - х| ANOVA и/или Tukey | Хи-квадрат|\n",
        "\n",
        "## ЩАГ 2: Определите соответствуют ли данные выбранным критериям?\n",
        "\n",
        "### Резюме\n",
        "\n",
        "\n",
        "- [T-критерий для одной выборки](https://statistics.laerd.com/spss-tutorials/one-sample-t-test-using-spss-statistics.php)\n",
        "    - Нет выбросов\n",
        "    - Даннные распределены нормально\n",
        "\n",
        "- [Независимый t-критерий (2-выборки)](https://statistics.laerd.com/statistical-guides/independent-t-test-statistical-guide.php)\n",
        "    - Нет выбросов\n",
        "    - Данные распределены нормально\n",
        "    - Дисперсии равны\n",
        "\n",
        "- [ANOVA](https://statistics.laerd.com/spss-tutorials/one-way-anova-using-spss-statistics.php)\n",
        "   - Нет выбросов\n",
        "   - Данные распределены нормально\n",
        "   - Дисперсии равны\n",
        "\n",
        "- [Хи квадрат](https://statistics.laerd.com/spss-tutorials/chi-square-test-for-association-using-spss-statistics.php)\n",
        "    - Обе переменные категариальные\n",
        "\n",
        "\n",
        "### Как проверить критерий\n",
        "\n",
        "#### 0. Удаление выбросов\n",
        "\n",
        "\n",
        "- t-критерий и ANOVA.\n",
        "- Используйте один из двух приведенных ниже методов для выявления выбросов:\n",
        "    - Используйте правило межквартильного диапазона Tukey's.\n",
        "    - Как правило, используйте абсолютное значение  Z-scores >3.\n",
        "- ВНИМАНИЕ: Метод IQR Тьюки удаляет больше выбросов, чем z-баллов. Позаботьтесь о выборе подходящего удаления выбросов.\n",
        "\n",
        "#### 1. **Проверка данных на Нормальность**\n",
        "\n",
        "- Используется для проверки следующие тесты:\n",
        "    - Тест на нормальность Д'Агостино-Пирсона<br>\n",
        "    ```scipy.stats.normaltest```\n",
        "    - Тест Шапиро-Вилика<br>\n",
        "    ```scipy.stats.shapiro```<br>\n",
        "\n",
        "\n",
        "- **1A. Если данные распределены нормально:**\n",
        "\n",
        "    - ** Переходим к шагу \\#2**, тестирование равенство дисперсий.\n",
        "    \n",
        "    \n",
        "- **1B. Данные распределены нормально:**\n",
        "    \n",
        "    > **Проверьте, достаточно ли велики размеры вашей выборки (n), чтобы безопасно игнорировать предположение о нормальности? (см. таблицу ниже)**\n",
        "\n",
        "    - **Если ваш N достаточно большой:**\n",
        "        - **Перейдем к предположению #2, проверяя предположение о равной дисперсии.\n",
        "   - **Если ваша группа N НЕДОСТАТОЧНО велика**:  \n",
        "        - **Перейдите к шагу 3,** выбрав непараметрическую версию t-критерия\n",
        "\n",
        "| Параметрический тест| Рекомендации по размеру выборки для ненормальных данных|\n",
        "| --- | --- |\n",
        "| 1-выборка t - критерий| Больше 20|\n",
        "| 2-выборкиe t - критерий| Каждая выборка больше 15|\n",
        "| ANOVA|Для 2 -9 групп, для каждой группы n >= 15. <br>Для  10-12 груп, каждой n>20.|\n",
        "    \n",
        "\n",
        "#### 2. Тест на равенство дисперсий\n",
        "\n",
        " - Тест Левена<br>\n",
        "```scipy.stats.levene```\n",
        "\n",
        "- **Если вы не выполняете предположение о равной дисперсии:**\n",
        "    - Используйте Т-критерий Уэлча.\n",
        "        -для scipy, добавляем `equal_var=False` в `ttest_ind`\n",
        "        \n",
        "        \n",
        "- **При равенстве дисперсий:**\n",
        "    - Используйте t-критерий для 2 выборок.\n",
        "    - переходите к шагу 3.\n",
        "    \n",
        "\n",
        "#### 3. Выберите непараметрический эквивалент вашего t-критерия.\n",
        "\n",
        "\n",
        "> **Выбор между параметрическими и непараметрическими критериями**\n",
        "- [Choosing Between Parametric and Non-Parametric Tests](https://blog.minitab.com/blog/adventures-in-statistics-2/choosing-between-a-nonparametric-test-and-a-parametric-test)\n",
        "\n",
        "- **Выберите критерий в правом столбце «Непараметрический», который соответствует параметрическому t-критерию.**\n",
        "\n",
        "\n",
        "| Параметрические тесты (средние) |Непараметрические тесты (медианы)|\n",
        " | --- | --- |\n",
        " | 1-выборка t- критерий |  Уилкоксона |\n",
        " | 2-выборки t критерий | Тест Манна-Уитни|\n",
        " | ANOVA | Крускал-Уоллис |\n",
        "\n",
        "- Смотрите окончательную итоговую таблицу с функциями scipy.\n",
        "### Итоговая таблица с функциями\n",
        "\n",
        "| Parametric tests (means) | Function | Nonparametric tests (medians) | Function |\n",
        " | --- | --- | --- | --- |\n",
        " | **1-выборка t- критерий** |`scipy.stats.ttest_1samp()`|  **Уилкоксона** |`scipy.stats.wilcoxon`|\n",
        " | **2-выборки t критерий** |`scipy.stats.ttest_ind()` | **Тест Манна-Уитни** |`scipy.stats.mannwhitneyu()` |\n",
        " | **ANOVA** | `scipy.stats.f_oneway()` | **Крускал-Уоллис** | `scipy.stats.kruskal` |\n",
        "\n",
        "\n",
        "## Шаг 3: Интерпритация результатов\n",
        "\n",
        "- **Сравниваю p-value критерия с уровнем значимости.**\n",
        "\n",
        "- **Если p value  < $\\alpha$:**\n",
        "    - Отвергаю  нулевую гипотезу.\n",
        "    \n",
        "    \n",
        "- **If p<.05 AND you have multiple groups (i.e. ANOVA)**\n",
        "    - **Must run a pairwise Tukey's test to know which groups were significantly different.**\n",
        "    - [Tukey pairwise comparison test](https://www.statsmodels.org/stable/generated/statsmodels.stats.multicomp.pairwise_tukeyhsd.html)\n",
        "    - `statsmodels.stats.multicomp.pairwise_tukeyhsd`\n",
        "    \n",
        "    \n",
        "- Report statistical power (optional)\n",
        "\n",
        "#### Post-Hoc Functions:\n",
        "\n",
        "| Post-Hoc Tests/Calculatons|Function|\n",
        "|--- | --- |\n",
        "|**Tukey's Pairwise Comparisons** | `statsmodels.stats.multicomp.pairwise_tukeyhsd`|\n",
        "|**Effect Size**| `Cohens_d`|\n",
        "|**Statistical Power** | `statsmodels.stats.power`:<br>  `TTestIndPower` , `TTestPower`\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I_W66Z95lYkk"
      },
      "source": [
        "# SUMMARY TABLES - COMPLETE\n",
        "\n",
        "### Assumption Tests\n",
        "\n",
        "|Assumption test| Function |\n",
        "| --- | --- |\n",
        "| **Normality**| `scipy.stats.normaltest`|\n",
        "| **Equal Variance** | `scipy.stats.levene`|\n",
        "\n",
        "\n",
        "### Hypothesis Tests\n",
        "\n",
        "| Parametric tests (means) | Function | Nonparametric tests (medians) | Function |\n",
        "| --- | --- | --- | --- |\n",
        "| **1-sample t test** |`scipy.stats.ttest_1samp()`|  **1-sample Wilcoxon** |`scipy.stats.wilcoxon`|\n",
        "| **2-sample t test** |`scipy.stats.ttest_ind()` | **Mann-Whitney U test** |`scipy.stats.mannwhitneyu()`|\n",
        "| **One-Way ANOVA** | `scipy.stats.f_oneway()` | **Kruskal-Wallis** | `scipy.stats.kruskal` |\n",
        "\n",
        "\n",
        " ### Post-Hoc Tests/Calculations\n",
        "\n",
        " | Post-Hoc Tests/Calculatons|Function|\n",
        " |--- | --- |\n",
        " |**Tukey's Pairwise Comparisons** | `statsmodels.stats.multicomp.pairwise_tukeyhsd`|\n",
        " |**Effect Size**| `Cohens_d`|\n",
        " |**Statistical Power** | `statsmodels.stats.power`:<br>  `TTestIndPower` , `TTestPower`\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CaHHs0rRlYkk"
      },
      "source": [
        "# SUMMARY: HYPOTHESIS TESTING STEPS\n",
        "\n",
        "- Separate data in group vars.\n",
        "- Visualize data and calculate group n (size)\n",
        "\n",
        "    \n",
        "* Select the appropriate test based on type of comparison being made, the number of groups, the type of data.\n",
        "\n",
        "\n",
        "- For t-tests: test for the assumptions of normality and homogeneity of variance.\n",
        "\n",
        "    1. Check if sample sizes allow us to ignore assumptions, and if not:\n",
        "    2. **Test Assumption Normality**\n",
        "\n",
        "    3. **Test for Homogeneity of Variance**\n",
        "\n",
        "    4. **Choose appropriate test based upon the above**\n",
        "    \n",
        "* **Perform chosen statistical test, calculate effect size, and any post-hoc tests.**\n",
        "    - To perform post-hoc pairwise comparison testing\n",
        "    - Effect size calculation\n",
        "        - Cohen's d\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nd7MgG-8lYkl"
      },
      "source": [
        "# FUNCTIONS FROM STUDY GROUP\n",
        "\n",
        "```python\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "import scipy.stats as stats\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "def Cohen_d(group1, group2, correction = False):\n",
        "    \"\"\"Compute Cohen's d\n",
        "    d = (group1.mean()-group2.mean())/pool_variance.\n",
        "    pooled_variance= (n1 * var1 + n2 * var2) / (n1 + n2)\n",
        "\n",
        "    Args:\n",
        "        group1 (Series or NumPy array): group 1 for calculating d\n",
        "        group2 (Series or NumPy array): group 2 for calculating d\n",
        "        correction (bool): Apply equation correction if N<50. Default is False.\n",
        "            - Url with small ncorrection equation:\n",
        "                - https://www.statisticshowto.datasciencecentral.com/cohens-d/\n",
        "    Returns:\n",
        "        d (float): calculated d value\n",
        "         \n",
        "    INTERPRETATION OF COHEN's D:\n",
        "    > Small effect = 0.2\n",
        "    > Medium Effect = 0.5\n",
        "    > Large Effect = 0.8\n",
        "    \n",
        "    \"\"\"\n",
        "    import scipy.stats as stats\n",
        "    import scipy   \n",
        "    import numpy as np\n",
        "    N = len(group1)+len(group2)\n",
        "    diff = group1.mean() - group2.mean()\n",
        "\n",
        "    n1, n2 = len(group1), len(group2)\n",
        "    var1 = group1.var()\n",
        "    var2 = group2.var()\n",
        "\n",
        "    # Calculate the pooled threshold as shown earlier\n",
        "    pooled_var = (n1 * var1 + n2 * var2) / (n1 + n2)\n",
        "    \n",
        "    # Calculate Cohen's d statistic\n",
        "    d = diff / np.sqrt(pooled_var)\n",
        "    \n",
        "    ## Apply correction if needed\n",
        "    if (N < 50) & (correction==True):\n",
        "        d=d * ((N-3)/(N-2.25))*np.sqrt((N-2)/N)\n",
        "    return d\n",
        "\n",
        "\n",
        "#Your code here\n",
        "def find_outliers_Z(data):\n",
        "    \"\"\"Use scipy to calculate absolute Z-scores\n",
        "    and return boolean series where True indicates it is an outlier.\n",
        "\n",
        "    Args:\n",
        "        data (Series,or ndarray): data to test for outliers.\n",
        "\n",
        "    Returns:\n",
        "        [boolean Series]: A True/False for each row use to slice outliers.\n",
        "        \n",
        "    EXAMPLE USE:\n",
        "    >> idx_outs = find_outliers_df(df['AdjustedCompensation'])\n",
        "    >> good_data = df[~idx_outs].copy()\n",
        "    \"\"\"\n",
        "    import pandas as pd\n",
        "    import numpy as np\n",
        "    import scipy.stats as stats\n",
        "    import pandas as pd\n",
        "    import numpy as np\n",
        "    ## Calculate z-scores\n",
        "    zs = stats.zscore(data)\n",
        "    \n",
        "    ## Find z-scores >3 awayfrom mean\n",
        "    idx_outs = np.abs(zs)>3\n",
        "    \n",
        "    ## If input was a series, make idx_outs index match\n",
        "    if isinstance(data,pd.Series):\n",
        "        return pd.Series(idx_outs,index=data.index)\n",
        "    else:\n",
        "        return pd.Series(idx_outs)\n",
        "    \n",
        "    \n",
        "    \n",
        "def find_outliers_IQR(data):\n",
        "    \"\"\"Use Tukey's Method of outlier removal AKA InterQuartile-Range Rule\n",
        "    and return boolean series where True indicates it is an outlier.\n",
        "    - Calculates the range between the 75% and 25% quartiles\n",
        "    - Outliers fall outside upper and lower limits, using a treshold of  1.5*IQR the 75% and 25% quartiles.\n",
        "\n",
        "    IQR Range Calculation:    \n",
        "        res = df.describe()\n",
        "        IQR = res['75%'] -  res['25%']\n",
        "        lower_limit = res['25%'] - 1.5*IQR\n",
        "        upper_limit = res['75%'] + 1.5*IQR\n",
        "\n",
        "    Args:\n",
        "        data (Series,or ndarray): data to test for outliers.\n",
        "\n",
        "    Returns:\n",
        "        [boolean Series]: A True/False for each row use to slice outliers.\n",
        "        \n",
        "    EXAMPLE USE:\n",
        "    >> idx_outs = find_outliers_df(df['AdjustedCompensation'])\n",
        "    >> good_data = df[~idx_outs].copy()\n",
        "    \n",
        "    \"\"\"\n",
        "    df_b=data\n",
        "    res= df_b.describe()\n",
        "\n",
        "    IQR = res['75%'] -  res['25%']\n",
        "    lower_limit = res['25%'] - 1.5*IQR\n",
        "    upper_limit = res['75%'] + 1.5*IQR\n",
        "\n",
        "    idx_outs = (df_b>upper_limit) | (df_b<lower_limit)\n",
        "\n",
        "    return idx_outs\n",
        "\n",
        "\n",
        "\n",
        "def prep_data_for_tukeys(data):\n",
        "    \"\"\"Accepts a dictionary with group names as the keys\n",
        "    and pandas series as the values.\n",
        "    \n",
        "    Returns a dataframe ready for tukeys test:\n",
        "    - with a 'data' column and a 'group' column for sms.stats.multicomp.pairwise_tukeyhsd\n",
        "    \n",
        "    Example Use:\n",
        "    df_tukey = prep_data_for_tukeys(grp_data)\n",
        "    tukey = sms.stats.multicomp.pairwise_tukeyhsd(df_tukey['data'], df_tukey['group'])\n",
        "    tukey.summary()\n",
        "    \"\"\"\n",
        "    \n",
        "    df_tukey = pd.DataFrame(columns=['data','group'])\n",
        "    for k,v in  data.items():\n",
        "        grp_df = v.rename('data').to_frame()\n",
        "        grp_df['group'] = k\n",
        "        df_tukey=pd.concat([df_tukey, grp_df],axis=0)\n",
        "\n",
        "\t## New lines added to ensure compatibility with tukey's test\n",
        "    df_tukey['group'] = df_tukey['group'].astype('str')\n",
        "    df_tukey['data'] = df_tukey['data'].astype('float')\n",
        "    return df_tukey\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oTRCRjhflYkl"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "file_extension": ".py",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "mimetype": "text/x-python",
    "name": "python",
    "npconvert_exporter": "python",
    "pygments_lexer": "ipython3",
    "version": 3,
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}